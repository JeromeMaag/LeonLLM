{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defs for Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_bars(data_dict, title, y_label):\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    names = list(data_dict.keys())\n",
    "    values = [data_dict[name] for name in names]\n",
    "    colors = sns.color_palette(\"Paired\", len(names))\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        name = name.split(\"_\")[1] + \" \" + name.split(\"_\")[2]\n",
    "        name = name.replace(\"GPT\", \"GPT-2\")\n",
    "        bar = ax.bar(i, values[i], color=colors[i], label=name)\n",
    "        ax.bar(name, values[i], color=colors[i], label=name)\n",
    "        ax.text(\n",
    "            bar[0].get_x() + bar[0].get_width() / 2,\n",
    "            bar[0].get_height(),\n",
    "            f\"{values[i]:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.xticks(rotation=30, ha=\"right\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./results/plots/{title}_barplot.svg\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_bars_avg(data_dict, title, y_label):\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    names = list(data_dict.keys())\n",
    "    values = [data_dict[name] for name in names]\n",
    "    colors = sns.color_palette(\"Paired\", len(names))\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        name = name.split(\"_\")[0] + \" \" + name.split(\"_\")[1]\n",
    "        name = name.replace(\"GPT\", \"GPT-2\")\n",
    "        bar = ax.bar(i, values[i], color=colors[i], label=name)\n",
    "        ax.bar(name, values[i], color=colors[i], label=name)\n",
    "        ax.text(\n",
    "            bar[0].get_x() + bar[0].get_width() / 2,\n",
    "            bar[0].get_height(),\n",
    "            f\"{values[i]:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.xticks(rotation=30, ha=\"right\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./results/plots/{title}_barplot.svg\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_bars_csv(data_dict, title, y_label):\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    names = list(data_dict.keys())\n",
    "    values = [data_dict[name] for name in names]\n",
    "    colors = sns.color_palette(\"Paired\", len(names))\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        name = name.split(\"_\")[2] + \" \" + name.split(\"_\")[4]\n",
    "        name = name.replace(\"plus\", \"+\")\n",
    "        bar = ax.bar(i, values[i], color=colors[i], label=name)\n",
    "        ax.bar(name, values[i], color=colors[i], label=name)\n",
    "        ax.text(\n",
    "            bar[0].get_x() + bar[0].get_width() / 2,\n",
    "            bar[0].get_height(),\n",
    "            f\"{values[i]:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.xticks(rotation=30, ha=\"right\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./results/plots/{title}_barplot.svg\")\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate a Model\n",
    "Metrics: \n",
    "- Hard Position Accuracy\n",
    "- Legal Piece Moves Accuracy\n",
    "- Average Correct Plies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# modelname = \"D:/LEON Safe/Leon-LLM-Models/xLANplus/Leon-Chess_350k_0001_4E_PLUS/Leon-Chess_350k_0001_4E_PLUS\"  # Huggingface model name or local path\n",
    "\n",
    "\n",
    "modelname = \"Leon-LLM/Leon-Chess-71k-Plus\"  # Huggingface model name or local path\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate validation prediction on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.validation.validate_model import validate_model\n",
    "\n",
    "(\n",
    "    hard_position_accuracy,\n",
    "    legal_piece_moves_accuracy,\n",
    "    average_correct_plies,\n",
    "    error_frequencies,\n",
    "    hard_position_results,\n",
    "    legal_piece_moves_results,\n",
    "    sequence_results,\n",
    ") = validate_model(\n",
    "    model,\n",
    "    max_batch_size=100,\n",
    "    number_of_plies_to_generate=125,\n",
    "    number_of_sequences=10,\n",
    "    do_sequence_validation=True,\n",
    "    tokens_per_ply=4,\n",
    "    notation=\"xLANplus\",\n",
    "    left_padding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"hard_position_accuracy: {hard_position_accuracy}\\nLegal piece moves accuracy: {legal_piece_moves_accuracy}\\nAverage correct plies: {average_correct_plies}\\nError frequencies: {error_frequencies}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"hard_position_results: {hard_position_results}\\nLegal piece moves results: {legal_piece_moves_results}\\nSequence results: {sequence_results}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = modelname.split(\"/\")[-1] + \"_results.json\"\n",
    "\n",
    "\n",
    "results = {\n",
    "    \"hard_position_accuracy\": hard_position_accuracy,\n",
    "    \"legal_piece_moves_accuracy\": legal_piece_moves_accuracy,\n",
    "    \"average_correct_plies\": average_correct_plies,\n",
    "    \"error_frequencies\": error_frequencies,\n",
    "    \"hard_position_results\": hard_position_results,\n",
    "    \"legal_piece_moves_results\": legal_piece_moves_results,\n",
    "    \"sequence_results\": sequence_results,\n",
    "}\n",
    "\n",
    "\n",
    "with open(f\"./results/model_evaluations/{file_name}\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct and Incorrect Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Hard Positions and Legal Piece Move Positions for 1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"Leon-Chess-71k-Plus_results.json\"\n",
    "\n",
    "\n",
    "with open(f\"./results/model_evaluations/{file_name}\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "legal_piece_moves_results = data[\"legal_piece_moves_results\"]\n",
    "hard_position_results = data[\"hard_position_results\"]\n",
    "\n",
    "\n",
    "correct_hard_positions = []\n",
    "incorrect_hard_positions = []\n",
    "correct_legal_piece_moves = []\n",
    "incorrect_legal_piece_moves = []\n",
    "\n",
    "\n",
    "for result in hard_position_results:\n",
    "\n",
    "    position_id = result[0]\n",
    "    correctness = result[2]\n",
    "    if correctness:\n",
    "        correct_hard_positions.append(position_id)\n",
    "    else:\n",
    "        incorrect_hard_positions.append(position_id)\n",
    "\n",
    "for result in legal_piece_moves_results:\n",
    "    position_id = result[0]\n",
    "    correctness = result[3]\n",
    "    if correctness:\n",
    "        correct_legal_piece_moves.append(position_id)\n",
    "    else:\n",
    "        incorrect_legal_piece_moves.append(position_id)\n",
    "\n",
    "\n",
    "result_summary = {\n",
    "    \"correct_hard_positions\": correct_hard_positions,\n",
    "    \"incorrect_hard_positions\": incorrect_hard_positions,\n",
    "    \"correct_legal_piece_moves\": correct_legal_piece_moves,\n",
    "    \"incorrect_legal_piece_moves\": incorrect_legal_piece_moves,\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Correct Positions:\", result_summary[\"correct_hard_positions\"])\n",
    "print(\"Incorrect Positions:\", result_summary[\"incorrect_hard_positions\"])\n",
    "print(\"Correct Legal Piece Moves:\", result_summary[\"correct_legal_piece_moves\"])\n",
    "print(\"Incorrect Legal Piece Moves:\", result_summary[\"incorrect_legal_piece_moves\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Chess Boards with resualts of the hard positions metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.validation.validate_position import get_position_by_id\n",
    "from src.validation.validate_position import show_position_by_id\n",
    "import json\n",
    "\n",
    "file_name = \"Leon-Chess-71k-Plus_results.json\"\n",
    "\n",
    "\n",
    "with open(f\"./results/model_evaluations/{file_name}\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "hard_position_results = data[\"hard_position_results\"]\n",
    "\n",
    "for result in hard_position_results:\n",
    "\n",
    "    position_id = result[0]\n",
    "    predicted_move = result[1]\n",
    "    correctness = result[2]\n",
    "    correctness_status = \"Correct\" if correctness else \"Incorrect\"\n",
    "\n",
    "    print(f\"Position ID: {position_id}\")\n",
    "    print(f\"Predicted Move: {predicted_move}\")\n",
    "    print(f\"Correctness: {correctness_status}\")\n",
    "\n",
    "    print(get_position_by_id(position_id, metric=\"hard_positions\", notation=\"xLANplus\"))\n",
    "    show_position_by_id(position_id, metric=\"hard_positions\", notation=\"xLANplus\")\n",
    "    print(\"\\n\" + \"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Chess Boards with resualts of the legal piece moves metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.validation.validate_position import get_position_by_id\n",
    "from src.validation.validate_position import show_position_by_id\n",
    "\n",
    "import json\n",
    "\n",
    "file_name = \"Leon-Chess-71k-Plus_results.json\"\n",
    "\n",
    "\n",
    "with open(f\"./results/model_evaluations/{file_name}\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "legal_piece_moves_results = data[\"legal_piece_moves_results\"]\n",
    "\n",
    "for result in legal_piece_moves_results:\n",
    "    position_id = result[0]\n",
    "    predicted_move = result[1]\n",
    "    predicted_move_index = result[2]\n",
    "    correctness = result[3]\n",
    "    correctness_status = \"Correct\" if correctness else \"Incorrect\"\n",
    "\n",
    "    print(f\"Position ID: {position_id}\")\n",
    "    print(f\"Predicted Move: {predicted_move}\")\n",
    "    print(f\"Predicted Move Index: {predicted_move_index}\")\n",
    "    print(f\"Correctness: {correctness_status}\")\n",
    "\n",
    "    print(get_position_by_id(position_id, metric=\"board_state\", notation=\"xLANplus\"))\n",
    "    show_position_by_id(position_id, metric=\"board_state\", notation=\"xLANplus\")\n",
    "    print(\"\\n\" + \"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Hard Positions and Legal Piece Move Positions for multiple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compares different Models on Hard Positions\n",
    "- JSON Files needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src.validation.validate_position import get_position_by_id\n",
    "from src.validation.validate_position import show_position_by_id\n",
    "\n",
    "\n",
    "model_names = [\n",
    "    \"R1_GPT2_19k_4E_xLANplus\",\n",
    "    \"R5_GPT2_71k_4E_xLANplus\",\n",
    "    \"R2_GPT2_350k_4E_xLANplus\",\n",
    "    \"R3_Mamba_19k_4E_xLANplus\",\n",
    "    \"R6_Mamba_71k_4E_xLANplus\",\n",
    "    \"R4_Mamba_350k_4E_xLANplus\",\n",
    "]\n",
    "all_results = {}\n",
    "\n",
    "for modelname in model_names:\n",
    "\n",
    "    with open(f\"./results/model_evaluations/{modelname}.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    hard_position_results = data[\"hard_position_results\"]\n",
    "\n",
    "    for result in hard_position_results:\n",
    "\n",
    "        position_id = result[0]\n",
    "        predicted_move = result[1]\n",
    "        correctness = result[2]\n",
    "        correctness_status = \"Correct\" if correctness else \"Incorrect\"\n",
    "        if position_id not in all_results:\n",
    "            all_results[position_id] = []\n",
    "        all_results[position_id].append(\n",
    "            {\n",
    "                \"model\": modelname,\n",
    "                \"predicted_move\": predicted_move,\n",
    "                \"correctness_status\": correctness_status,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "for position_id, results in all_results.items():\n",
    "    print(f\"Position ID: {position_id}\")\n",
    "\n",
    "    print(get_position_by_id(position_id, metric=\"hard_positions\", notation=\"xLANplus\"))\n",
    "    show_position_by_id(position_id, metric=\"hard_positions\", notation=\"xLANplus\")\n",
    "    for result in results:\n",
    "        print(f\"Model: {result['model']}\")\n",
    "        print(f\"Predicted Move: {result['predicted_move']}\")\n",
    "        print(f\"Correctness: {result['correctness_status']}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compares different Models on Hard Positions\n",
    "- JSON Files needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from src.validation.validate_position import get_position_by_id\n",
    "from src.validation.validate_position import show_position_by_id\n",
    "\n",
    "model_names = [\n",
    "    \"R1_GPT2_19k_4E_xLANplus\",\n",
    "    \"R5_GPT2_71k_4E_xLANplus\",\n",
    "    \"R2_GPT2_350k_4E_xLANplus\",\n",
    "    \"R3_Mamba_19k_4E_xLANplus\",\n",
    "    \"R6_Mamba_71k_4E_xLANplus\",\n",
    "    \"R4_Mamba_350k_4E_xLANplus\",\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for modelname in model_names:\n",
    "    with open(f\"./results/model_evaluations/{modelname}.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    legal_piece_moves_results = data[\"legal_piece_moves_results\"]\n",
    "    for result in legal_piece_moves_results:\n",
    "        position_id = result[0]\n",
    "        predicted_moves = result[1]\n",
    "        correct_moves = result[2]\n",
    "        correctness = result[3]\n",
    "        correctness_status = \"Correct\" if correctness else \"Incorrect\"\n",
    "\n",
    "        if position_id not in all_results:\n",
    "            all_results[position_id] = []\n",
    "\n",
    "        all_results[position_id].append(\n",
    "            {\n",
    "                \"model\": modelname,\n",
    "                \"predicted_moves\": predicted_moves,\n",
    "                \"correct_moves\": correct_moves,\n",
    "                \"correctness_status\": correctness_status,\n",
    "            }\n",
    "        )\n",
    "for position_id, results in all_results.items():\n",
    "    print(f\"Position ID: {position_id}\")\n",
    "    print(get_position_by_id(position_id, metric=\"board_state\", notation=\"xLANplus\"))\n",
    "    show_position_by_id(position_id, metric=\"board_state\", notation=\"xLANplus\")\n",
    "\n",
    "    for result in results:\n",
    "        print(f\"Model: {result['model']}\")\n",
    "        print(f\"Predicted Moves: {result['predicted_moves']}\")\n",
    "        print(f\"Correct Moves: {result['correct_moves']}\")\n",
    "        print(f\"Correctness: {result['correctness_status']}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the Evaluations saved as CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legal Piece Moves for multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from src.validation.validate_position import get_position_by_id\n",
    "from src.validation.validate_position import show_position_by_id\n",
    "\n",
    "\n",
    "model_names = [\n",
    "    \"V27_GPT2_19k_4E_xLAN_legal_piece_moves_results.csv\",\n",
    "    \"V28_GPT2_71k_4E_xLAN_legal_piece_moves_results.csv\",\n",
    "    \"V32_GPT2_350k_4E_xLAN_legal_piece_moves_results.csv\",\n",
    "    \"V29_GPT2_19k_4E_xLANplus_legal_piece_moves_results.csv\",\n",
    "    \"V30_GPT2_71k_4E_xLANplus_legal_piece_moves_results.csv\",\n",
    "    \"V31_GPT2_350k_4E_xLANplus_legal_piece_moves_results.csv\",\n",
    "]\n",
    "all_results = {}\n",
    "\n",
    "\n",
    "for modelname in model_names:\n",
    "\n",
    "    with open(f\"./results/model_evaluations/{modelname}\", \"r\") as file:\n",
    "\n",
    "        reader = csv.DictReader(file)\n",
    "\n",
    "        for row in reader:\n",
    "            position_id = row[\"Position ID\"]\n",
    "            predicted_moves = row[\"Predicted Move\"]\n",
    "            correct_moves = row[\"Correct Moves\"]\n",
    "            correctness = row[\"Correctness\"]\n",
    "            correctness_status = (\n",
    "                \"Correct\" if correctness.lower() == \"true\" else \"Incorrect\"\n",
    "            )\n",
    "            if position_id not in all_results:\n",
    "                all_results[position_id] = []\n",
    "            all_results[position_id].append(\n",
    "                {\n",
    "                    \"model\": modelname,\n",
    "                    \"predicted_moves\": predicted_moves,\n",
    "                    \"correct_moves\": correct_moves,\n",
    "                    \"correctness_status\": correctness_status,\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "for position_id, results in all_results.items():\n",
    "    position_id = position_id.strip()\n",
    "    position_id = int(position_id)\n",
    "    print(f\"Position ID: {position_id}\")\n",
    "\n",
    "    print(get_position_by_id(position_id, metric=\"board_state\", notation=\"xLANplus\"))\n",
    "    show_position_by_id(position_id, metric=\"board_state\", notation=\"xLANplus\")\n",
    "    for result in results:\n",
    "\n",
    "        print(f\"Model: {result['model']}\")\n",
    "        print(f\"Predicted Moves: {result['predicted_moves']}\")\n",
    "        print(f\"Correct Moves: {result['correct_moves']}\")\n",
    "        print(f\"Correctness: {result['correctness_status']}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the accuracies as Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "model_names = [\n",
    "    \"V27_GPT2_19k_4E_xLAN_legal_piece_moves_results.csv\",\n",
    "    \"V29_GPT2_19k_4E_xLANplus_legal_piece_moves_results.csv\",\n",
    "    \"V28_GPT2_71k_4E_xLAN_legal_piece_moves_results.csv\",\n",
    "    \"V30_GPT2_71k_4E_xLANplus_legal_piece_moves_results.csv\",\n",
    "    \"V32_GPT2_350k_4E_xLAN_legal_piece_moves_results.csv\",\n",
    "    \"V31_GPT2_350k_4E_xLANplus_legal_piece_moves_results.csv\",\n",
    "]\n",
    "\n",
    "accuracy_results = {}\n",
    "\n",
    "for modelname in model_names:\n",
    "    total_positions = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with open(f\"./results/model_evaluations/{modelname}\", \"r\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            total_positions += 1\n",
    "            correctness = row[\"Correctness\"]\n",
    "            if correctness.lower() == \"true\":\n",
    "                correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_positions\n",
    "    accuracy_results[modelname] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars_csv(\n",
    "    accuracy_results,\n",
    "    \"Legal Piece Moves Accuracy Comparison xLAN vs xLAN+\",\n",
    "    \"Legal Piece Moves Accuracy (%)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Positions for multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from src.validation.validate_position import get_position_by_id\n",
    "from src.validation.validate_position import show_position_by_id\n",
    "\n",
    "\n",
    "\n",
    "# Dictionary to store results for each model by position ID\n",
    "\n",
    "\n",
    "model_names = [\n",
    "    \"V27_GPT2_19k_4E_xLAN_hard_positions_results.csv\",\n",
    "    \"V28_GPT2_71k_4E_xLAN_hard_positions_results.csv\",\n",
    "    \"V32_GPT2_350k_4E_xLAN_hard_positions_results.csv\",\n",
    "    \"V29_GPT2_19k_4E_xLANplus_hard_positions_results.csv\",\n",
    "    \"V30_GPT2_71k_4E_xLANplus_hard_positions_results.csv\",\n",
    "    \"V31_GPT2_350k_4E_xLANplus_hard_positions_results.csv\",\n",
    "]\n",
    "\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through each model\n",
    "\n",
    "\n",
    "for modelname in model_names:\n",
    "\n",
    "\n",
    "    # Load the CSV data for the current model\n",
    "\n",
    "    with open(f\"./results/model_evaluations/{modelname}\", \"r\") as file:\n",
    "\n",
    "        reader = csv.DictReader(file)\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "            position_id = row[\"Position ID\"]\n",
    "\n",
    "            predicted_move = row[\"Predicted Move\"]\n",
    "\n",
    "            correctness = row[\"Correctness\"]\n",
    "\n",
    "            correctness_status = (\n",
    "                \"Correct\" if correctness.lower() == \"true\" else \"Incorrect\"\n",
    "            )\n",
    "\n",
    "            if position_id not in all_results:\n",
    "\n",
    "                all_results[position_id] = []\n",
    "\n",
    "            all_results[position_id].append(\n",
    "                {\n",
    "                    \"model\": modelname,\n",
    "                    \"predicted_move\": predicted_move,\n",
    "                    \"correctness_status\": correctness_status,\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "# Print the results for each position\n",
    "\n",
    "\n",
    "for position_id, results in all_results.items():\n",
    "\n",
    "    position_id = position_id.strip()\n",
    "\n",
    "    # Convert string to number\n",
    "\n",
    "    position_id = int(position_id)\n",
    "\n",
    "    print(f\"Position ID: {position_id}\")\n",
    "\n",
    "\n",
    "    print(get_position_by_id(position_id, metric=\"hard_positions\", notation=\"xLANplus\"))\n",
    "\n",
    "    show_position_by_id(position_id, metric=\"hard_positions\", notation=\"xLANplus\")\n",
    "\n",
    "\n",
    "    for result in results:\n",
    "\n",
    "\n",
    "        print(f\"Model: {result['model']}\")\n",
    "\n",
    "        print(f\"Predicted Move: {result['predicted_move']}\")\n",
    "\n",
    "        print(f\"Correctness: {result['correctness_status']}\")\n",
    "\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the accuracies as Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Dictionary to store results for each model by position ID\n",
    "model_names = [\n",
    "    \"V27_GPT2_19k_4E_xLAN_hard_positions_results.csv\",\n",
    "    \"V29_GPT2_19k_4E_xLANplus_hard_positions_results.csv\",\n",
    "    \"V28_GPT2_71k_4E_xLAN_hard_positions_results.csv\",\n",
    "    \"V30_GPT2_71k_4E_xLANplus_hard_positions_results.csv\",\n",
    "    \"V32_GPT2_350k_4E_xLAN_hard_positions_results.csv\",\n",
    "    \"V31_GPT2_350k_4E_xLANplus_hard_positions_results.csv\",\n",
    "]\n",
    "accuracy_results = {}\n",
    "\n",
    "for modelname in model_names:\n",
    "    total_positions = 0\n",
    "    correct_predictions = 0\n",
    "    # Load the CSV data for the current model\n",
    "    with open(f\"./results/model_evaluations/{modelname}\", \"r\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            total_positions += 1\n",
    "            correctness = row[\"Correctness\"]\n",
    "            if correctness.lower() == \"true\":\n",
    "                correct_predictions += 1\n",
    "    accuracy = correct_predictions / total_positions\n",
    "    accuracy_results[modelname] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars_csv(\n",
    "    accuracy_results,\n",
    "    \"Hard Position Accuracy Comparison xLAN vs xLAN+\",\n",
    "    \"Hard Position Accuracy (%)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Plots for IDs in Legal Piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model_names = [\n",
    "    # \"R1_GPT2_19k_4E_xLANplus\",\n",
    "    # \"R5_GPT2_71k_4E_xLANplus\",\n",
    "    \"R2_GPT2_350k_4E_xLANplus\",\n",
    "    # \"R3_Mamba_19k_4E_xLANplus\",\n",
    "    # \"R6_Mamba_71k_4E_xLANplus\",\n",
    "    \"R4_Mamba_350k_4E_xLANplus\",\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "# Iterate through each model\n",
    "for modelname in model_names:\n",
    "    # Load the JSON data for the current model\n",
    "    with open(f\"./results/model_evaluations/{modelname}.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    # Extract the required lists\n",
    "    legal_piece_moves_results = data[\"legal_piece_moves_results\"]\n",
    "    # Process the data to get the positions and print the required details\n",
    "\n",
    "    for result in legal_piece_moves_results:\n",
    "        position_id = result[0]\n",
    "        predicted_moves = result[1]\n",
    "        correct_moves = result[2]\n",
    "        correctness = result[3]\n",
    "        correctness_status = \"Correct\" if correctness else \"Incorrect\"\n",
    "        if position_id not in all_results:\n",
    "            all_results[position_id] = []\n",
    "        all_results[position_id].append(\n",
    "            {\n",
    "                \"model\": modelname,\n",
    "                \"correctness_status\": correctness_status,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Separate the results into odd and even position IDs\n",
    "odd_results = {k: v for k, v in all_results.items() if int(k) % 2 != 0}\n",
    "even_results = {k: v for k, v in all_results.items() if int(k) % 2 == 0}\n",
    "\n",
    "\n",
    "# Function to prepare data for plotting\n",
    "def prepare_plot_data(results, model_name):\n",
    "    position_ids = []\n",
    "    statuses = []\n",
    "\n",
    "    for position_id, result_list in results.items():\n",
    "        for result in result_list:\n",
    "            if result[\"model\"] == model_name:\n",
    "                position_ids.append(position_id)\n",
    "                statuses.append(result[\"correctness_status\"])\n",
    "\n",
    "    return position_ids, statuses\n",
    "\n",
    "\n",
    "# Function to create a bar plot for a specific model\n",
    "def create_bar_plot(model_name, position_ids, statuses, title):\n",
    "    unique_positions = list(set(position_ids))\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(unique_positions))\n",
    "\n",
    "    correct_counts = [0] * len(unique_positions)\n",
    "    incorrect_counts = [0] * len(unique_positions)\n",
    "\n",
    "    for i, pos_id in enumerate(unique_positions):\n",
    "        count_correct = sum(\n",
    "            1\n",
    "            for j in range(len(position_ids))\n",
    "            if position_ids[j] == pos_id and statuses[j] == \"Correct\"\n",
    "        )\n",
    "        count_incorrect = sum(\n",
    "            1\n",
    "            for j in range(len(position_ids))\n",
    "            if position_ids[j] == pos_id and statuses[j] == \"Incorrect\"\n",
    "        )\n",
    "        correct_counts[i] = count_correct\n",
    "        incorrect_counts[i] = count_incorrect\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    ax.bar(index, correct_counts, bar_width, label=\"Correct\")\n",
    "    ax.bar(index, incorrect_counts, bar_width, bottom=correct_counts, label=\"Incorrect\")\n",
    "\n",
    "    ax.set_xlabel(\"Position IDs\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(f\"{title} - {model_name}\")\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(unique_positions, rotation=90)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create bar plots for each model for odd and even results\n",
    "for model_name in model_names:\n",
    "    odd_position_ids, odd_statuses = prepare_plot_data(odd_results, model_name)\n",
    "    even_position_ids, even_statuses = prepare_plot_data(even_results, model_name)\n",
    "    create_bar_plot(\n",
    "        model_name,\n",
    "        odd_position_ids,\n",
    "        odd_statuses,\n",
    "        \"Correctness Status for Odd Position IDs\",\n",
    "    )\n",
    "    create_bar_plot(\n",
    "        model_name,\n",
    "        even_position_ids,\n",
    "        even_statuses,\n",
    "        \"Correctness Status for Even Position IDs\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Plots for all 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_names = [\n",
    "    \"R1_GPT2_19k_4E_xLANplus\",\n",
    "    \"R3_Mamba_19k_4E_xLANplus\",\n",
    "    \"R5_GPT2_71k_4E_xLANplus\",\n",
    "    \"R6_Mamba_71k_4E_xLANplus\",\n",
    "    \"R2_GPT2_350k_4E_xLANplus\",\n",
    "    \"R4_Mamba_350k_4E_xLANplus\",\n",
    "]\n",
    "\n",
    "all_hard_position_accuracies = {}\n",
    "all_legal_piece_moves_accuracies = {}\n",
    "all_average_correct_plies = {}\n",
    "\n",
    "for modelname in model_names:\n",
    "    with open(f\"./results/model_evaluations/{modelname}.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    hard_position_accuracy = data[\"hard_position_accuracy\"]\n",
    "    legal_piece_moves_accuracy = data[\"legal_piece_moves_accuracy\"]\n",
    "    average_correct_plies = data[\"average_correct_plies\"]\n",
    "    all_hard_position_accuracies[modelname] = hard_position_accuracy\n",
    "    all_legal_piece_moves_accuracies[modelname] = legal_piece_moves_accuracy\n",
    "    all_average_correct_plies[modelname] = average_correct_plies\n",
    "\n",
    "print(all_hard_position_accuracies)\n",
    "print(all_legal_piece_moves_accuracies)\n",
    "print(all_average_correct_plies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plot_bars(\n",
    "    all_hard_position_accuracies,\n",
    "    \"Hard Position Accuracy Comparison GPT-2 vs Mamba\",\n",
    "    \"Hard Position Accuracy (%)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plot_bars(\n",
    "    all_legal_piece_moves_accuracies,\n",
    "    \"Legal Piece Moves Accuracy Comparison GPT-2 vs Mamba\",\n",
    "    \"Legal Piece Moves Accuracy (%)\",\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plot_bars(\n",
    "    all_average_correct_plies,\n",
    "    \"Average Number of Correct Plies Comparison GPT-2 vs Mamba\",\n",
    "    \"Average Number of Correct Plies\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Averge Number of correct plies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data:\n",
    "xLAN_19k = 2.31\n",
    "xLAN_71k = 14.42\n",
    "xLAN_350k = 35.98\n",
    "xLANplus_19k = 10.25\n",
    "xLANplus_71k = 24.15\n",
    "xLANplus_350k = 44.80\n",
    "\n",
    "# Plot the results\n",
    "plot_bars_avg(\n",
    "    {\n",
    "        \"xLAN_19k\": xLAN_19k,\n",
    "        \"xLANplus_19k\": xLANplus_19k,\n",
    "        \"xLAN_71k\": xLAN_71k,\n",
    "        \"xLANplus_71k\": xLANplus_71k,\n",
    "        \"xLAN_350k\": xLAN_350k,\n",
    "        \"xLANplus_350k\": xLANplus_350k,\n",
    "    },\n",
    "    \"Average Number of Correct Plies Comparison xLAN vs xLAN+\",\n",
    "    \"Average Number of Correct Plies\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot  different Plus notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data average number of correct plies for xLAN+ variations:\n",
    "xLAN_71k_max = 17.49\n",
    "xLANchk_71k_max = 23.56\n",
    "xLANcap_71k_max = 25.00\n",
    "xLANplus_71k_max = 25.86\n",
    "\n",
    "# Plot the results\n",
    "\n",
    "plot_bars_avg(\n",
    "    {\n",
    "        \"xLAN_71k\": xLAN_71k_max,\n",
    "        \"xLANchk_71k\": xLANchk_71k_max,\n",
    "        \"xLANcap_71k\": xLANcap_71k_max,\n",
    "        \"xLANplus_71k\": xLANplus_71k_max,\n",
    "    },\n",
    "    \"Average Number of Correct Plies Comparison xLAN+ Variations\",\n",
    "    \"Average Number of Correct Plies\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data hard position accuracy for xLAN+ variations:\n",
    "xLAN_71k = 0.78\n",
    "xLANchk_71k = 0.79\n",
    "xLANcap_71k = 0.81\n",
    "xLANplus_71k = 0.81\n",
    "\n",
    "# Plot the results\n",
    "plot_bars_avg(\n",
    "    {\n",
    "        \"xLAN_71k\": xLAN_71k,\n",
    "        \"xLANchk_71k\": xLANchk_71k,\n",
    "        \"xLANcap_71k\": xLANcap_71k,\n",
    "        \"xLANplus_71k\": xLANplus_71k,\n",
    "    },\n",
    "    \"Hard Position Accuracy Comparison xLAN+ Variations\",\n",
    "    \"Hard Position Accuracy (%)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data legal piece moves accuracy for xLAN+ variations:\n",
    "xLAN_71k = 0.79\n",
    "xLANchk_71k = 0.78\n",
    "xLANcap_71k = 0.80\n",
    "xLANplus_71k = 0.81\n",
    "\n",
    "# Plot the results\n",
    "\n",
    "plot_bars_avg(\n",
    "    {\n",
    "        \"xLAN_71k\": xLAN_71k,\n",
    "        \"xLANchk_71k\": xLANchk_71k,\n",
    "        \"xLANcap_71k\": xLANcap_71k,\n",
    "        \"xLANplus_71k\": xLANplus_71k,\n",
    "    },\n",
    "    \"Legal Piece Moves Accuracy Comparison xLAN+ Variations\",\n",
    "    \"Legal Piece Moves Accuracy (%)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
